{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'Greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there', 'Hello', 'Good day'], 'responses': ['Hey:-)', 'Hello, thanks for visiting', 'Hi there, What can I do for you', 'hi there, how can I help?']}, {'tag': 'Placements', 'patterns': ['Is there any Placements in your College?', 'Do we have any Placements in your College?', 'Is There Placement In College?'], 'responses': ['yes,we have good Placements in our College']}, {'tag': 'Admission', 'patterns': ['How To Apply For The Admission For Bsc, Msc, Puc, Professional, Evening College, Certification Course ?', 'How We Will Get The Admission For Bsc, Msc, Puc, Professional, Evening College, Certification Course ?', 'How To Get Admission For Bsc, Msc, Puc, Professional, Evening College, Certification Course ?'], 'responses': ['First you need apply through our college website,and then you will get a date for entrance exam,after that you have interview,if you select in that round,you will get seat in our college']}, {'tag': 'Internship', 'patterns': ['How many month we need to do internship', 'What is the internship time-period we have to do?', 'Is it possible to complete our internship before the time scheduled?'], 'responses': ['Internship will be completed in the given period of time']}, {'tag': 'Canteen', 'patterns': ['What Items are available in the Canteen?', 'Do we get non-veg food in canteen?', 'What are the Items that we can get it from the Canteen?'], 'responses': ['we can get all fast-foods,samosa,chai,chochalates,biscuits,icecreams and many more']}, {'tag': 'Outreach program', 'patterns': ['What are the Rules in Outreach Program?', 'What if we Break the rules,What type of Punishments we get?', 'What happens when we Break the Rules?'], 'responses': ['You should not do consumption of Alcohol,Smoking and should maintain disciplane in the program and if you break the rules,we will punish you for a period of time']}, {'tag': 'Timings', 'patterns': ['What are the timings allowed to students to use the lab?', 'What are the timings maintain by the college office?', 'What is the regular timing of the college?'], 'responses': ['The Regular timings of college is from morning 8.00 am to 4.00 pm']}, {'tag': 'Contact Information', 'patterns': ['Whom Should we contact for Admission?', 'Can you send phone numbers of office?', 'Who should we contact to apply for a Scholarship? '], 'responses': ['first you need visit  our college website,then you will get all information regarding addmission,fees,phone no etc.']}, {'tag': 'Hostel facility', 'patterns': ['Do we have any Hostel inside the Campus?', 'do you all has boys hostel in your college?', 'do you all has girls hostel inside the college?'], 'responses': ['Yes,We have both boys and girls hostels located inside the college']}, {'tag': 'Fees', 'patterns': ['What Will Be The Fees For Parking?', 'How Much Is The Fees For Parking?', 'What Is The Fees For Parking?'], 'responses': ['for two wheeler 2000 for one year and for four wheeler vechicle 4000 for one year']}, {'tag': 'Sports activity encouragement', 'patterns': ['Do You All Encourage For Sports?', 'Will You Encourage For Sports?', 'Do We Have Encouragement For Sports?'], 'responses': ['yes,we will encourage the students for sports who all intrested']}, {'tag': 'Campus', 'patterns': ['What Are The Things Do You All Have In The Campus?', 'What Do You All Have In The Campus?', 'What All Are There In The Campus?'], 'responses': ['we have many things in our campus,you can go through the college website']}, {'tag': 'About courses', 'patterns': ['How much Cut-off for MSC Big Data in entrance', 'What is the cut-off for in the entrance exam?', 'What is the Cut off for Big Data Analytics Course?'], 'responses': ['minimum 60% we needed to join in our college']}, {'tag': 'Library_location', 'patterns': ['how to go to library?', 'Where is the library?', \"Where's library located?\"], 'responses': ['We have huge library which is located in Arrupple block or A block and PG library is in PG Block first floor']}, {'tag': 'Ending', 'patterns': ['Bye', 'Okay thank you bye', \"that's all thanks\", 'okay bye', 'nothing else', \"that's all for now\", 'will get back to you later'], 'responses': ['Thanks for visiting, Have a good day, Bye', 'Have a great day ahead, Bye for now']}]}\n"
     ]
    }
   ],
   "source": [
    "my=open('C:/Users/sai kiran Reddy/Desktop/chat/pytorch-chatbot-master/data.json','r')\n",
    "jsondata=my.read()\n",
    "intents=json.loads(jsondata)\n",
    "print(intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "my=open('C:/Users/sai kiran Reddy/Desktop/chat/pytorch-chatbot-master/data.json','r')\n",
    "jsondata=my.read()\n",
    "intents=json.loads(jsondata)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(sentence):\n",
    "    \"\"\"\n",
    "    split sentence into array of words/tokens\n",
    "    a token can be a word or punctuation character, or number\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(sentence)\n",
    "\n",
    "\n",
    "def stem(word):\n",
    "    \"\"\"\n",
    "    stemming = find the root form of the word\n",
    "    examples:\n",
    "    words = [\"organize\", \"organizes\", \"organizing\"]\n",
    "    words = [stem(w) for w in words]\n",
    "    -> [\"organ\", \"organ\", \"organ\"]\n",
    "    \"\"\"\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "    \"\"\"\n",
    "    return bag of words array:\n",
    "    1 for each known word that exists in the sentence, 0 otherwise\n",
    "    example:\n",
    "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
    "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
    "    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
    "    \"\"\"\n",
    "    # stem each word\n",
    "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
    "    # initialize bag with 0 for each word\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words: \n",
    "            bag[idx] = 1\n",
    "\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 patterns\n",
      "15 tags: ['About courses', 'Admission', 'Campus', 'Canteen', 'Contact Information', 'Ending', 'Fees', 'Greeting', 'Hostel facility', 'Internship', 'Library_location', 'Outreach program', 'Placements', 'Sports activity encouragement', 'Timings']\n",
      "117 unique stemmed words: [\"'s\", ',', 'a', 'admiss', 'all', 'allow', 'analyt', 'ani', 'anyon', 'appli', 'are', 'avail', 'back', 'be', 'befor', 'big', 'boy', 'break', 'bsc', 'by', 'bye', 'campu', 'can', 'canteen', 'certif', 'colleg', 'complet', 'contact', 'cours', 'cut', 'cut-off', 'data', 'day', 'do', 'els', 'encourag', 'entranc', 'even', 'exam', 'fee', 'food', 'for', 'from', 'get', 'girl', 'go', 'good', 'ha', 'happen', 'have', 'hello', 'hey', 'hi', 'hostel', 'how', 'if', 'in', 'insid', 'internship', 'is', 'it', 'item', 'lab', 'later', 'librari', 'locat', 'maintain', 'mani', 'month', 'msc', 'much', 'need', 'non-veg', 'noth', 'now', 'number', 'of', 'off', 'offic', 'okay', 'our', 'outreach', 'park', 'phone', 'placement', 'possibl', 'profession', 'program', 'puc', 'punish', 'regular', 'rule', 'schedul', 'scholarship', 'send', 'should', 'sport', 'student', 'thank', 'that', 'the', 'there', 'thing', 'time', 'time-period', 'to', 'type', 'use', 'we', 'what', 'when', 'where', 'who', 'whom', 'will', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    # add to tag list\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = tokenize(pattern)\n",
    "        # add to our words list\n",
    "        all_words.extend(w)\n",
    "        # add to xy pair\n",
    "        xy.append((w, tag))\n",
    "\n",
    "# stem and lower each word\n",
    "ignore_words = ['?', '.', '!']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "# remove duplicates and sort\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "\n",
    "print(len(xy), \"patterns\")\n",
    "print(len(tags), \"tags:\", tags)\n",
    "print(len(all_words), \"unique stemmed words:\", all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    # X: bag of words for each pattern_sentence\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(words)\n",
    "        # if y would be one-hot, we must apply\n",
    "        # labels = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_name = \"Sam\"\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "while True:\n",
    "    # sentence = \"do you use credit cards?\"\n",
    "    sentence = input(\"You: \")\n",
    "    if sentence == \"Thankyou\":\n",
    "        break\n",
    "\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    output = model(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                reply=random.choice(intent['responses'])\n",
    "                print(f\"{bot_name}\",reply)\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's chat! (type 'quit' to exit)\n",
    "You: hi\n",
    "Sam Hello, thanks for visiting\n",
    "You: Thankyou"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
